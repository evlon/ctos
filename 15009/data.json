{"id":"15009","name":"唐宇迪人工智能开发工程师：机器学习算法详解","lecturer":"想了解人工智能职业规划和职业薪水的同学","descriptionText":"阿里巴巴、人工智能协会专家联合打造。通过学习能够独立完成基于机器学习与深度学习算法对亿级数据挖掘与建模，优秀学员将获得直通企业的推荐资格。","chapters":[{"id":"32566","name":"课程导学","courseId":"15009","sections":[{"id":"301623","name":"人工智能开发工程师课程导学","courseId":"15009","url":"/15009/0_0_301623.m3u8"}]},{"id":"63010","name":"K临近算法","courseId":"15009","sections":[{"id":"523416","name":"K临近算法概述","courseId":"15009","url":"/15009/1_0_523416.m3u8"},{"id":"523452","name":"模型评估","courseId":"15009","url":"/15009/1_1_523452.m3u8"},{"id":"523451","name":"数据预处理","courseId":"15009","url":"/15009/1_2_523451.m3u8"},{"id":"523450","name":"sklearn库与功能","courseId":"15009","url":"/15009/1_3_523450.m3u8"},{"id":"523449","name":"多变量KNN模型","courseId":"15009","url":"/15009/1_4_523449.m3u8"}]},{"id":"63011","name":"线性回归算法","courseId":"15009","sections":[{"id":"523448","name":"回归问题概述","courseId":"15009","url":"/15009/2_0_523448.m3u8"},{"id":"523447","name":"误差项定义","courseId":"15009","url":"/15009/2_1_523447.m3u8"},{"id":"523446","name":"独立同分布的意义","courseId":"15009","url":"/15009/2_2_523446.m3u8"},{"id":"523445","name":"似然函数的作用","courseId":"15009","url":"/15009/2_3_523445.m3u8"},{"id":"523444","name":"参数求解","courseId":"15009","url":"/15009/2_4_523444.m3u8"}]},{"id":"63012","name":"逻辑回归算法","courseId":"15009","sections":[{"id":"523443","name":"逻辑回归算法原理","courseId":"15009","url":"/15009/3_0_523443.m3u8"},{"id":"523442","name":"化简与求解","courseId":"15009","url":"/15009/3_1_523442.m3u8"}]},{"id":"63013","name":"决策树算法","courseId":"15009","sections":[{"id":"523441","name":"决策树算法概述","courseId":"15009","url":"/15009/4_0_523441.m3u8"},{"id":"523440","name":"熵的作用","courseId":"15009","url":"/15009/4_1_523440.m3u8"},{"id":"523439","name":"信息增益原理","courseId":"15009","url":"/15009/4_2_523439.m3u8"},{"id":"523438","name":"决策树构造实例","courseId":"15009","url":"/15009/4_3_523438.m3u8"},{"id":"523437","name":"信息增益率与GINI系数","courseId":"15009","url":"/15009/4_4_523437.m3u8"},{"id":"523436","name":"预剪枝方法","courseId":"15009","url":"/15009/4_5_523436.m3u8"},{"id":"523435","name":"后剪枝方法","courseId":"15009","url":"/15009/4_6_523435.m3u8"},{"id":"523434","name":"回归问题解决","courseId":"15009","url":"/15009/4_7_523434.m3u8"}]},{"id":"63014","name":"随机森林与集成算法","courseId":"15009","sections":[{"id":"523433","name":"随机森林算法原理","courseId":"15009","url":"/15009/5_0_523433.m3u8"},{"id":"523432","name":"随机森林优势与特征重要性指标","courseId":"15009","url":"/15009/5_1_523432.m3u8"},{"id":"523431","name":"提升算法概述","courseId":"15009","url":"/15009/5_2_523431.m3u8"},{"id":"523430","name":"stacking堆叠模型","courseId":"15009","url":"/15009/5_3_523430.m3u8"}]},{"id":"63015","name":"贝叶斯算法","courseId":"15009","sections":[{"id":"523429","name":"贝叶斯要解决的问题","courseId":"15009","url":"/15009/6_0_523429.m3u8"},{"id":"523428","name":"贝叶斯公式推导","courseId":"15009","url":"/15009/6_1_523428.m3u8"},{"id":"523427","name":"垃圾邮件过滤实例","courseId":"15009","url":"/15009/6_2_523427.m3u8"}]},{"id":"63017","name":"K-means算法","courseId":"15009","sections":[{"id":"523426","name":"Kmeans算法概述","courseId":"15009","url":"/15009/7_0_523426.m3u8"},{"id":"523425","name":"Kmeans工作流程","courseId":"15009","url":"/15009/7_1_523425.m3u8"},{"id":"523424","name":"Kmeans迭代可视化展示","courseId":"15009","url":"/15009/7_2_523424.m3u8"}]},{"id":"63018","name":"线性判别算法","courseId":"15009","sections":[{"id":"523423","name":"线性判别分析要解决的问题","courseId":"15009","url":"/15009/8_0_523423.m3u8"},{"id":"523422","name":"线性判别分析要优化的目标","courseId":"15009","url":"/15009/8_1_523422.m3u8"},{"id":"523421","name":"线性判别分析求解","courseId":"15009","url":"/15009/8_2_523421.m3u8"}]},{"id":"63019","name":"PCA主成分分析算法","courseId":"15009","sections":[{"id":"523420","name":"PCA降维概述","courseId":"15009","url":"/15009/9_0_523420.m3u8"},{"id":"523419","name":"PCA要优化的目标","courseId":"15009","url":"/15009/9_1_523419.m3u8"},{"id":"523418","name":"PCA求解","courseId":"15009","url":"/15009/9_2_523418.m3u8"},{"id":"523417","name":"PCA降维实例","courseId":"15009","url":"/15009/9_3_523417.m3u8"}]}]}